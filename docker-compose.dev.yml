
services:
  # 0) 開発環境  ────────────────────────────
  develop:
    build:
      context: .
      dockerfile: .devcontainer/Dockerfile
    container_name: develop_container
    # コンテナを起動し続けるためのコマンド
    command: sleep infinity
    volumes:
      # プロジェクト全体をコンテナ内にマウント
      - .:/workspaces/lecture-ai-engineering-final:cached
      # Docker-from-Docker を実現するためにDockerソケットをマウント
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - backend-net

  # 1) 抽出サービス  ────────────────────────────
  extraction:
    build: ./backend/extraction_service        # ← Step1 の Dockerfile
    container_name: extraction_service
    ports:
      - "8080:8080"
    environment:
      # FastAPI が MLflow にロギングするとき用
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - AWS_REGION=us-east-1
      - DDB_TABLE=SlideVectors
      - AWS_PROFILE=lecture-dev-final
      - AWS_SDK_LOAD_CONFIG=1        # ← これを追加
      - AWS_PAGER= ""           # ← これで “less が無い” 問題を無効化
      - AWS_CONFIG_FILE=/root/.aws/config   # ← 明示パスを追加
    volumes:
      - ./slides:/data
      - type: volume
        source: awscreds         # ← named volume
        target: /root/.aws

    depends_on:
      - mlflow
    networks:
      - backend-net

  # 2) MLflow Tracking Server  ─────────────────
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.22.1
    container_name: mlflow_server
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root /mlruns
      --host 0.0.0.0 --port 5000
    volumes:
      - ./mlruns:/mlruns         # run・artifact 保存先
    ports:
      - "5000:5000"
    networks:
      - backend-net

networks:
  backend-net:
    driver: bridge

volumes:
  awscreds:
    external: true   # ← 追加
    name: awscreds   # ← docker volume create で作った名前
