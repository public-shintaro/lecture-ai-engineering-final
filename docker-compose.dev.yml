
services:
  # 0) 開発環境  ────────────────────────────
  develop:
    build:
      context: .
      dockerfile: .devcontainer/Dockerfile
    container_name: develop_container
    # コンテナを起動し続けるためのコマンド
    command: sleep infinity
    volumes:
      # プロジェクト全体をコンテナ内にマウント
      - .:/workspaces/lecture-ai-engineering-final:cached
      # Docker-from-Docker を実現するためにDockerソケットをマウント
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - backend-net

  # 1) 抽出サービス  ────────────────────────────
  extraction:
    build:
      context: .  # ビルドコンテキストをプロジェクトルートに設定
      dockerfile: backend/extraction_service/Dockerfile # Dockerfileの場所を明記
    container_name: extraction_service
    ports:
      - "8000:8000"
    environment:
      - AWS_REGION=${AWS_REGION}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_SESSION_TOKEN=${AWS_SESSION_TOKEN} # AWS SSO等の一時的な認証情報を使っている場合
      - MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI}
      - AWS_PAGER=""
    volumes:
      - ./slides:/data

    depends_on:
      - mlflow
    networks:
      - backend-net

  # 2) MLflow Tracking Server  ─────────────────
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.22.1
    container_name: mlflow_server
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root /mlruns
      --host 0.0.0.0 --port 5000
    volumes:
      - ./mlruns:/mlruns         # run・artifact 保存先
    ports:
      - "5000:5000"
    networks:
      - backend-net

# 3) LocalStack  ──────────────────────────────
  localstack:
    image: localstack/localstack:3.5
    ports:
      - "4566:4566"      # LocalStackのEdge port
    environment:
      - SERVICES=s3,sqs
      - LS_LOG=info
    volumes:
      - "./.localstack:/var/lib/localstack" # データを永続化
    networks:
      - backend-net

networks:
  backend-net:
    driver: bridge
